{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    },
    {
     "data": {
      "text/plain": "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n0                  5.1               3.5                1.4               0.2\n1                  4.9               3.0                1.4               0.2\n2                  4.7               3.2                1.3               0.2\n3                  4.6               3.1                1.5               0.2\n4                  5.0               3.6                1.4               0.2\n..                 ...               ...                ...               ...\n145                6.7               3.0                5.2               2.3\n146                6.3               2.5                5.0               1.9\n147                6.5               3.0                5.2               2.0\n148                6.2               3.4                5.4               2.3\n149                5.9               3.0                5.1               1.8\n\n[150 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal length (cm)</th>\n      <th>sepal width (cm)</th>\n      <th>petal length (cm)</th>\n      <th>petal width (cm)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "import pandas as pd\n",
    "#1. Iris 데이터셋 로드\n",
    "iris = load_iris()\n",
    "print(iris.feature_names)\n",
    "df = pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "(1.0,\n array([[19,  0,  0],\n        [ 0, 13,  0],\n        [ 0,  0, 13]]),\n '              precision    recall  f1-score   support\\n\\n      setosa       1.00      1.00      1.00        19\\n  versicolor       1.00      1.00      1.00        13\\n   virginica       1.00      1.00      1.00        13\\n\\n    accuracy                           1.00        45\\n   macro avg       1.00      1.00      1.00        45\\nweighted avg       1.00      1.00      1.00        45\\n')"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "#데이터 분할\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "#로지스틱 회귀 모델 생성\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "# 성능 평가\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, target_names=iris.target_names)\n",
    "\n",
    "# 결과 출력\n",
    "accuracy, conf_matrix, class_report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.7656\n",
      "Epoch [200/1000], Loss: 0.6453\n",
      "Epoch [300/1000], Loss: 0.6113\n",
      "Epoch [400/1000], Loss: 0.5871\n",
      "Epoch [500/1000], Loss: 0.5693\n",
      "Epoch [600/1000], Loss: 0.5561\n",
      "Epoch [700/1000], Loss: 0.5463\n",
      "Epoch [800/1000], Loss: 0.5391\n",
      "Epoch [900/1000], Loss: 0.5337\n",
      "Epoch [1000/1000], Loss: 0.5297\n",
      "Test Loss (MSE): 0.5560\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 데이터 로드\n",
    "california = fetch_california_housing()\n",
    "X, y = california.data, california.target\n",
    "\n",
    "# 데이터 표준화 (선형 회귀에서는 스케일링이 중요함)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = y.reshape(-1, 1)  # PyTorch 텐서 변환을 위해 reshape\n",
    "\n",
    "# 훈련/테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PyTorch 텐서 변환\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 선형 회귀 모델 정의\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)  # 단순 선형 회귀\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# 모델 초기화\n",
    "input_dim = X_train.shape[1]  # 특성 개수\n",
    "model = LinearRegressionModel(input_dim)\n",
    "\n",
    "# 손실 함수 및 최적화 함수 정의\n",
    "criterion = nn.MSELoss() #손실 함수\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 모델 평가\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)\n",
    "    test_loss = criterion(y_pred, y_test_tensor)\n",
    "    print(f'Test Loss (MSE): {test_loss.item():.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 직접 구현한 선형회귀 모델\n",
    "\n",
    "## 데이터 생성 및 초기값 세팅"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#1. 데이터 생성\n",
    "xdata = np.array([1,2,3,4],dtype=np.float32) # 입력 데이터(특성)\n",
    "ydata = np.array([2,4,6,8],dtype=np.float32) # 출력 데이터(목표값)\n",
    "\n",
    "\n",
    "#2. 초기 가중치 설정\n",
    "w = 0.0 #가중치 초기값\n",
    "learning_rate = 0.01 #학습률\n",
    "n_epochs = 100 # 반복 횟수 (에포크)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 선형모델 / 손실함수 / 기울기 계산 함수 정의"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : Weight = 1.6063,Loss=1.6094\n",
      "Epoch 20 : Weight = 1.9225,Loss=0.0624\n",
      "Epoch 30 : Weight = 1.9847,Loss=0.0024\n",
      "Epoch 40 : Weight = 1.9970,Loss=0.0001\n",
      "Epoch 50 : Weight = 1.9994,Loss=0.0000\n",
      "Epoch 60 : Weight = 1.9999,Loss=0.0000\n",
      "Epoch 70 : Weight = 2.0000,Loss=0.0000\n",
      "Epoch 80 : Weight = 2.0000,Loss=0.0000\n",
      "Epoch 90 : Weight = 2.0000,Loss=0.0000\n",
      "Epoch 100 : Weight = 2.0000,Loss=0.0000\n"
     ]
    }
   ],
   "source": [
    "# 선형 모델 정의\n",
    "def predict(_x,_w):\n",
    "    return _x * _w # 예측값 : 단순 선형 모델 Y = w*X\n",
    "\n",
    "#손실 함수 정의(평균 제곱 오차, MSE)\n",
    "def loss(_y,_y_pred):\n",
    "    return((_y_pred-_y) ** 2).mean() # 손실 계산\n",
    "\n",
    "# 기울기 계산\n",
    "def gradient(X,y,y_pred):\n",
    "    return np.dot(2 * (y_pred-y),X)/len(y) #평균 기울기\n",
    "\n",
    "#경사하강법 알고리즘\n",
    "for epoch in range(n_epochs) :\n",
    "    #예측값 계산\n",
    "    y_pred = predict(xdata,w)\n",
    "\n",
    "    #손실계산\n",
    "    l = loss(ydata,y_pred)\n",
    "    #기울기 계산\n",
    "    grad = gradient(xdata,ydata,y_pred)\n",
    "\n",
    "    #가중치 업데이트\n",
    "    w -= learning_rate * grad # w = w-(learning_rate * 기울기)\n",
    "\n",
    "    if(epoch +1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch +1} : Weight = {w:.4f},Loss={l:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
